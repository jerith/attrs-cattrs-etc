{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b. nested config (with validators)\n",
    "\n",
    "This is the same code as before, except I've added some explicit validators so we get runtime errors instead of `mypy` warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation helpers\n",
    "from attr import validators as av\n",
    "\n",
    "def dict_of(key_type, value_type):\n",
    "    return av.deep_mapping(av.instance_of(key_type), av.instance_of(value_type))\n",
    "    \n",
    "def list_of(item_type):\n",
    "    return av.deep_iterable(av.instance_of(item_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s(frozen=True)\n",
    "class SourceBase:\n",
    "    \"Base class: ad-hoc interface and some common behaviour.\"\n",
    "\n",
    "    name: str = attr.ib()\n",
    "    # We strip the type field out of the source dict during parsing. This\n",
    "    # attrib puts it back during serialization so we can read what we wrote.\n",
    "    type: str = attr.ib(init=False)\n",
    "\n",
    "    @type.default\n",
    "    def _type_default(self):\n",
    "        return self._source_type\n",
    "\n",
    "    _logger = None\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        return f\"{self._source_type}:{self.name}\"\n",
    "\n",
    "    @property\n",
    "    def logger(self):\n",
    "        if self._logger is None:\n",
    "            # Because we (and all our subclasses) are frozen, we need to cheat.\n",
    "            logger = _sources_logger.child(self.displayname)\n",
    "            object.__setattr__(self, \"_logger\", logger)\n",
    "        return self._logger\n",
    "\n",
    "    async def fetch(self, dest_dir):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s(frozen=True)\n",
    "class Manifest(SourceBase):\n",
    "    \"Fetch a file that is assumed to contain YAML.\"\n",
    "\n",
    "    _source_type = \"manifest\"\n",
    "\n",
    "    url: str = attr.ib()\n",
    "\n",
    "    async def fetch(self, dest_dir):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s(frozen=True)\n",
    "class HelmChartReleaseVars:\n",
    "    \"Things helm wnats that aren't template variables.\"\n",
    "\n",
    "    name: Optional[str] = attr.ib(default=None)\n",
    "    namespace: Optional[str] = attr.ib(default=None)\n",
    "\n",
    "\n",
    "@attr.s(frozen=True)\n",
    "class HelmChart(SourceBase):\n",
    "    \"Fetch a helm chart and render it to a single YAML file.\"\n",
    "\n",
    "    _source_type = \"chart\"\n",
    "\n",
    "    repo: str = attr.ib()\n",
    "    version: str = attr.ib()\n",
    "    templatevars: Dict[str, str] = attr.ib(factory=dict, validator=dict_of(str, str))\n",
    "    releasevars: HelmChartReleaseVars = attr.ib(\n",
    "        factory=HelmChartReleaseVars, validator=av.instance_of(HelmChartReleaseVars))\n",
    "\n",
    "    async def fetch(self, dest_dir):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s(frozen=True)\n",
    "class ArchivePath:\n",
    "    \"Complicated path glob matcher.\"\n",
    "\n",
    "    path: str = attr.ib()\n",
    "    dest: str = attr.ib(default=\"\")\n",
    "\n",
    "    @path.validator\n",
    "    def _path_validator(self, attribute, value):\n",
    "        for seg in value.split(\"/\")[:-1]:\n",
    "            if seg == \"**\":\n",
    "                raise ValueError(\"** may only appear at the end of a path\")\n",
    "\n",
    "    def match(self, path) -> Optional[str]:\n",
    "        pass\n",
    "\n",
    "\n",
    "@attr.s(frozen=True)\n",
    "class Archive(SourceBase):\n",
    "    \"Fetch an archive and extracts a subset of the files within it.\"\n",
    "\n",
    "    _source_type = \"archive\"\n",
    "\n",
    "    url: str = attr.ib()\n",
    "    paths: List[ArchivePath] = attr.ib(factory=list, validator=list_of(ArchivePath))\n",
    "\n",
    "    async def fetch(self, dest_dir):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MAP = {\"chart\": HelmChart, \"manifest\": Manifest, \"archive\": Archive}\n",
    "\n",
    "Source = Union[HelmChart, Manifest, Archive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s(frozen=True)\n",
    "class Config:\n",
    "    \"Structured config object parsed populated from YAML file.\"\n",
    "\n",
    "    sources: List[Source] = attr.ib(validator=list_of((HelmChart, Manifest, Archive)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
